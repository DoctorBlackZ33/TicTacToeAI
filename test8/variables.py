layer_count=2
layer_size=9
dropout_rate=0.1
initial_learning_rate=0.001

episodes=15000
synch_every_n_episodes=15
min_memory_size=200
alpha=0.1
gamma=0.3
batch_size=64
epsilon=1
epsilon_decay=0.9992
epsilon_min=0.1
win=1
draw=0.5
lose=-1
valid_action=0.1
invalid_action=-1