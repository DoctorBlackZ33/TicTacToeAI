layer_sizes=[256,128,64]
dropout_rate=0.1
initial_learning_rate=0.001

episodes=5000
synch_every_n_episodes = 40
max_memory_size = 10000
min_memory_size= 300
alpha=0.05
alpha_decay = 0.9999
gamma=0.4 #redundant as of right now, gamma_build_up_speed replaced this
gamma_build_up_speed=100
batch_size=32
epsilon=1
epsilon_decay=0.9999
epsilon_min=0.2
win=1
draw=0.5
lose=-1
valid_action=0.01
invalid_action=-1