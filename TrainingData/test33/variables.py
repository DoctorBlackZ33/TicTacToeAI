layer_sizes=[256,128,64]
dropout_rate=0.3
initial_learning_rate=0.001

episodes=15000
synch_every_n_episodes = 100
max_memory_size = 15000
min_memory_size= 10000
alpha=0.0001
alpha_decay = 0.9999
gamma=0.4 #redundant as of right now, gamma_build_up_speed replaced this
gamma_build_up_speed=100
batch_size=4096
epsilon=1
epsilon_decay=0.9999
epsilon_min=0.2
win=1
draw=0.5
lose=-1
valid_action=0.01
invalid_action=-1