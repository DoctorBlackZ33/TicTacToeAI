layer_sizes=[256,128,64]
dropout_rate=0.1
initial_learning_rate=0.001

episodes=2000
synch_every_n_episodes = 10
max_memory_size = 15000
min_memory_size= 1000
alpha=0.1
alpha_decay = 0.9999
gamma=0.4 #redundant as of right now, gamma_build_up_speed replaced this
gamma_build_up_speed=100
batch_size=256
epsilon=1
epsilon_decay=0.9999
epsilon_min=0.2
win=1
draw=0.5
lose=-1
valid_action=0.01
invalid_action=-1