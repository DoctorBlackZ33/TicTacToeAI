layer_count=2
layer_size=9
dropout_rate=0.1
initial_learning_rate=0.001

episodes=20000
synch_every_n_episodes=15
min_memory_size=1000
alpha=0.05
gamma=0.9
batch_size=64
epsilon=1
epsilon_decay=0.9992
epsilon_min=0.1
win=1
draw=0.5
lose=-1
valid_action=0.1
invalid_action=-1